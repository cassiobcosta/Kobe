{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b643d84-f913-4a05-8b5c-af040428bd5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hard_dependencies, dependency, missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\compat\\__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplatform\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     is_numpy_dev,\n\u001b[0;32m     17\u001b[0m     np_version_under1p19,\n\u001b[0;32m     18\u001b[0m     np_version_under1p20,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     pa_version_under1p01,\n\u001b[0;32m     22\u001b[0m     pa_version_under2p0,\n\u001b[0;32m     23\u001b[0m     pa_version_under3p0,\n\u001b[0;32m     24\u001b[0m     pa_version_under4p0,\n\u001b[0;32m     25\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_typing.py:78\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m     npt: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# array-like\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m ArrayLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtensionArray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m]\n\u001b[0;32m     79\u001b[0m AnyArrayLike \u001b[38;5;241m=\u001b[39m Union[ArrayLike, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# scalars\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'ndarray'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing, metrics, model_selection\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from pycaret.classification import *\n",
    "import pycaret.classification as pc\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "if 'inline_rc' not in dir():\n",
    "    inline_rc = dict(mpl.rcParams)\n",
    "\n",
    "SEED = 7\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c31c2c-bacc-4ee3-a77c-e3b5d52ad857",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update(inline_rc)\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 15}\n",
    "mpl.rc('font', **font)\n",
    "lines = {'linewidth' : 2}\n",
    "mpl.rc('lines', **lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "29b8f4c5-87f1-4fe7-a35f-256da4efa79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_name = 'modelo_projeto_kobe'\n",
    "min_precision = 0.75\n",
    "model_version = -1 # recuperar a ultima versao\n",
    "nexamples = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ded5b-e794-470e-8460-62fa8b362494",
   "metadata": {},
   "source": [
    "Diagrama do Pipeline do Projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e5b37-5ba4-4697-8899-a42c3867d8ce",
   "metadata": {},
   "source": [
    "https://github.com/cassiobcosta/Kobe/blob/main/Apresenta%C3%A7%C3%A3o1.jpg\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Apresenta%C3%A7%C3%A3o1.jpg >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e781adc1",
   "metadata": {},
   "source": [
    "Neste momento torna-se necessário variar os pipelines de forma que poderemos aproveitar os dados estruturados para avaliar e verificar se os experimentos foram bem feitos e se pode haver uma melhoria nos dados descritos.\n",
    "\n",
    "Para isso é preciso criar um pipeline para ter um referencial dos modelos criados e guardar os dados dos modelos. Podemos ter os artefatos,métricas e parametros utilizados e testar diferentes modelos para achar o melhor modelo para validar os dados e utilizá-los da melhor maneira.\n",
    "\n",
    "É possível através deste pipeline separarmos o que será utilizado em desenvolvimento e em seguida colocar em produção os dados utilizados.\n",
    "\n",
    "Após a validação dos modelos colocados em desenvolvimento, pode ser colocado o modelo em produção para que possa ser utilizado nas APIs selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbd761-3906-4b7e-9aa1-ed33297b85af",
   "metadata": {},
   "source": [
    "Inicio dos Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "780feb34-95d1-45df-99fd-c7c8e71bfcda",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "(sqlite3.OperationalError) no such table: experiments\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage \nFROM experiments \nWHERE experiments.name = ? AND experiments.lifecycle_stage IN (?, ?)]\n[parameters: ('Projeto Kobe Bryant', 'active', 'deleted')]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\base.py:1900\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1900\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 736\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: experiments",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\db\\utils.py:82\u001b[0m, in \u001b[0;36m_get_managed_session_maker.<locals>.make_managed_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m     session\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRAGMA case_sensitive_like = true;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m session\n\u001b[0;32m     83\u001b[0m session\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\tracking\\sqlalchemy_store.py:462\u001b[0m, in \u001b[0;36mSqlAlchemyStore.get_experiment_by_name\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    460\u001b[0m stages \u001b[38;5;241m=\u001b[39m LifecycleStage\u001b[38;5;241m.\u001b[39mview_type_to_stages(ViewType\u001b[38;5;241m.\u001b[39mALL)\n\u001b[0;32m    461\u001b[0m experiment \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 462\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSqlExperiment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_eager_experiment_query_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSqlExperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSqlExperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlifecycle_stage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_or_none\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m )\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mto_mlflow_entity() \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\orm\\query.py:2849\u001b[0m, in \u001b[0;36mQuery.one_or_none\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[38;5;124;03m\"\"\"Return at most one result or raise an exception.\u001b[39;00m\n\u001b[0;32m   2827\u001b[0m \n\u001b[0;32m   2828\u001b[0m \u001b[38;5;124;03mReturns ``None`` if the query selects\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2847\u001b[0m \n\u001b[0;32m   2848\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mone_or_none()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\orm\\query.py:2907\u001b[0m, in \u001b[0;36mQuery._iter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2906\u001b[0m statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statement_20()\n\u001b[1;32m-> 2907\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_sa_orm_load_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2911\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2913\u001b[0m \u001b[38;5;66;03m# legacy: automatically set scalars, unique\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\orm\\session.py:1712\u001b[0m, in \u001b[0;36mSession.execute\u001b[1;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, **kw)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_for_bind(bind)\n\u001b[1;32m-> 1712\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_20\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_state_cls:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\base.py:1705\u001b[0m, in \u001b[0;36mConnection._execute_20\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_10style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_10style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\sql\\elements.py:333\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\base.py:1572\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[0;32m   1564\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1565\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1566\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1570\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1571\u001b[0m )\n\u001b[1;32m-> 1572\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\base.py:1943\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1942\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1943\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1944\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1945\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\base.py:2124\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2124\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqlalchemy_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\base.py:1900\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1900\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sqlalchemy\\engine\\default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 736\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: experiments\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage \nFROM experiments \nWHERE experiments.name = ? AND experiments.lifecycle_stage IN (?, ?)]\n[parameters: ('Projeto Kobe Bryant', 'active', 'deleted')]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [165]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#sqlite:///mlruns.db\u001b[39;00m\n\u001b[0;32m      4\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProjeto Kobe Bryant\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     experiment_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mcreate_experiment(experiment_name)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\tracking\\fluent.py:1042\u001b[0m, in \u001b[0;36mget_experiment_by_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Experiment]:\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;124;03m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\tracking\\client.py:566\u001b[0m, in \u001b[0;36mMlflowClient.get_experiment_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Experiment]:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:226\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_experiment_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    :param name: The experiment name.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    :return: :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\tracking\\sqlalchemy_store.py:469\u001b[0m, in \u001b[0;36mSqlAlchemyStore.get_experiment_by_name\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    460\u001b[0m stages \u001b[38;5;241m=\u001b[39m LifecycleStage\u001b[38;5;241m.\u001b[39mview_type_to_stages(ViewType\u001b[38;5;241m.\u001b[39mALL)\n\u001b[0;32m    461\u001b[0m experiment \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    462\u001b[0m     session\u001b[38;5;241m.\u001b[39mquery(SqlExperiment)\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_eager_experiment_query_options())\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;241m.\u001b[39mone_or_none()\n\u001b[0;32m    468\u001b[0m )\n\u001b[1;32m--> 469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mto_mlflow_entity() \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\contextlib.py:131\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\db\\utils.py:89\u001b[0m, in \u001b[0;36m_get_managed_session_maker.<locals>.make_managed_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy\u001b[38;5;241m.\u001b[39mexc\u001b[38;5;241m.\u001b[39mSQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     88\u001b[0m     session\u001b[38;5;241m.\u001b[39mrollback()\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(message\u001b[38;5;241m=\u001b[39me, error_code\u001b[38;5;241m=\u001b[39mBAD_REQUEST)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     91\u001b[0m     session\u001b[38;5;241m.\u001b[39mrollback()\n",
      "\u001b[1;31mMlflowException\u001b[0m: (sqlite3.OperationalError) no such table: experiments\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage \nFROM experiments \nWHERE experiments.name = ? AND experiments.lifecycle_stage IN (?, ?)]\n[parameters: ('Projeto Kobe Bryant', 'active', 'deleted')]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "# Para usar o sqlite como repositorio\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "#sqlite:///mlruns.db\n",
    "experiment_name = 'Projeto Kobe Bryant'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13494f14-1148-4057-9d77-8aeaf104cb7d",
   "metadata": {},
   "source": [
    "Pipeline para a Preparação dos Dados Kobe Bryant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f34ba35d-410a-44fc-a6fa-cd38878ed671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Bases de Dados **\n",
      "xtrain (16228, 7)\n",
      "data_operation (4057, 7)\n",
      "Columns: Index(['lat', 'lon', 'minutes_remaining', 'period', 'playoffs',\n",
      "       'shot_distance', 'shot_made_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# COLOCAR RUN DE LEITURA DE DADOS\n",
    "# PARAMETROS: top_features,\n",
    "# METRICS: SHAPE de cada base de dados\n",
    "# ARTIFACTS: nenhum\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "    df_kobe = pd.read_csv('kobe_dataset.csv',sep=',')\n",
    "    kobe_target_col = 'shot_made_flag'\n",
    "    df_kobe_2p = df_kobe[df_kobe['shot_type'] == '2PT Field Goal']\n",
    "    df_kobe_3p = df_kobe[df_kobe['shot_type'] == '3PT Field Goal']\n",
    "    df_kobe_2p = df_kobe_2p[['lat','lon','minutes_remaining','period', 'playoffs','shot_distance','shot_made_flag']]\n",
    "    df_kobe_3p = df_kobe_3p[['lat','lon','minutes_remaining','period', 'playoffs','shot_distance','shot_made_flag']]\n",
    "    df_kobe_2p = df_kobe_2p.dropna()\n",
    "    df_kobe_3p = df_kobe_3p.dropna()\n",
    "    test_size = 0.2\n",
    "    \n",
    "    # Separar parte para compor a base de operacao\n",
    "    xtrain, data_operation, ytrain, ytest = model_selection.train_test_split(df_kobe_2p, \n",
    "                                                                            df_kobe_2p[kobe_target_col],\n",
    "                                                                            test_size=test_size)\n",
    "    \n",
    "    data_novelty = df_kobe_3p.copy()\n",
    "\n",
    "    xtrain.to_parquet('Data/Processed/data_filtered.parquet')\n",
    "    data_operation.to_parquet('Data/Processed/base_8020.parquet')\n",
    "    data_novelty.to_parquet('Data/Processed/base_kobe_novidade.parquet')\n",
    "\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"test_size\", test_size)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"data_dev\", df_kobe_2p.shape[0])\n",
    "    mlflow.log_metric(\"data_operation\", data_operation.shape[0])\n",
    "   \n",
    "    \n",
    "mlflow.end_run()\n",
    "\n",
    "print('** Bases de Dados **')\n",
    "print(f'xtrain {xtrain.shape}')\n",
    "print(f'data_operation {data_operation.shape}')\n",
    "print(f'Columns: {df_kobe_2p.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8ee5351f-715d-4858-92e7-e16613073b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2PT Field Goal    24271\n",
       "3PT Field Goal     6426\n",
       "Name: shot_type, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kobe['shot_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d412c4b-5e23-4caf-842a-3ef4b64ab00e",
   "metadata": {},
   "source": [
    "Pipeline para os Treinamentos dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO TREINAMENTO\n",
    "\n",
    "Streamlit - Pode ser utilizado para a criação dos Dashboards\n",
    "\n",
    "MLFlow - É utilizado para registrar os experimentos e treinamentos da base dos dados além de salvar artefatos, parametros e métricas\n",
    "\n",
    "PyCaret - Verifica o melhor modelo da base através dos parametros a serem utilizados, gera os artefatos e além das bases treinados\n",
    "\n",
    "Scikit-Learn - É utiliado para calcular as métricas geradas no treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048143d-732a-4866-b4e1-41115ce64ceb",
   "metadata": {},
   "source": [
    "Pipeline para o Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "91fd2f92-e7cb-4e10-b227-0ccc6179f691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  [logs] PyCaret Supervised Module\n",
      "INFO  [logs] ML Usecase: classification\n",
      "INFO  [logs] version 2.3.10\n",
      "INFO  [logs] Initializing setup()\n",
      "INFO  [logs] setup(target=shot_made_flag, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree', 'ks': 'KS Statistic Plot'}, train_size=0.8, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=True, experiment_name=Projeto Black Mamba, experiment_custom_tags=None, log_plots=['auc', 'confusion_matrix', 'feature'], log_profile=False, log_data=False, silent=True, verbose=False, profile=False, profile_kwargs=None, display=None)\n",
      "INFO  [logs] Checking environment\n",
      "INFO  [logs] python_version: 3.8.13\n",
      "INFO  [logs] python_build: ('default', 'Mar 28 2022 06:59:08')\n",
      "INFO  [logs] machine: AMD64\n",
      "INFO  [logs] platform: Windows-10-10.0.19044-SP0\n",
      "INFO  [logs] Memory: svmem(total=16543780864, available=8044322816, percent=51.4, used=8499458048, free=8044322816)\n",
      "INFO  [logs] Physical Core: 4\n",
      "INFO  [logs] Logical Core: 8\n",
      "INFO  [logs] Checking libraries\n",
      "INFO  [logs] pd==1.4.4\n",
      "INFO  [logs] numpy==1.23.1\n",
      "INFO  [logs] sklearn==0.23.2\n",
      "INFO  [logs] lightgbm==3.3.2\n",
      "WARNI [logs] catboost not found\n",
      "WARNI [logs] xgboost not found\n",
      "INFO  [logs] mlflow==1.28.0\n",
      "INFO  [logs] Checking Exceptions\n",
      "INFO  [logs] Declaring global variables\n",
      "INFO  [logs] USI: f3ae\n",
      "INFO  [logs] pycaret_globals: {'_ml_usecase', 'create_model_container', 'dashboard_logger', 'master_model_container', 'display_container', 'fold_generator', '_internal_pipeline', '_available_plots', 'y', 'seed', '_all_models_internal', 'exp_name_log', 'fix_imbalance_param', 'prep_pipe', '_all_models', 'pycaret_globals', 'fold_groups_param_full', 'n_jobs_param', 'target_param', 'X_train', 'iterative_imputation_iters_param', 'y_test', 'log_plots_param', 'experiment__', '_all_metrics', 'fold_shuffle_param', 'transform_target_method_param', 'gpu_param', 'X_test', 'transform_target_param', 'fix_imbalance_method_param', 'fold_param', 'logging_param', 'USI', '_gpu_n_jobs_param', 'imputation_classifier', 'html_param', 'fold_groups_param', 'X', 'data_before_preprocess', 'imputation_regressor', 'stratify_param', 'y_train'}\n",
      "INFO  [logs] Preparing display monitor\n",
      "INFO  [logs] Importing libraries\n",
      "INFO  [logs] Copying data for preprocessing\n",
      "INFO  [logs] Declaring preprocessing parameters\n",
      "INFO  [logs] Creating preprocessing pipeline\n",
      "INFO  [logs] Preprocessing pipeline created successfully\n",
      "ERROR [logs] (Process Exit): setup has been interupted with user command 'quit'. setup must rerun.\n",
      "INFO  [logs] Creating global containers\n",
      "INFO  [logs] Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)\n",
      "WARNI [logs] Couldn't import xgboost.XGBClassifier\n",
      "WARNI [logs] Couldn't import catboost.CatBoostClassifier\n",
      "WARNI [logs] Couldn't import xgboost.XGBClassifier\n",
      "WARNI [logs] Couldn't import catboost.CatBoostClassifier\n",
      "INFO  [logs] Creating grid variables\n",
      "INFO  [logs] Logging experiment in MLFlow\n",
      "INFO  [logs] SubProcess save_model() called ==================================\n",
      "INFO  [logs] Initializing save_model()\n",
      "INFO  [logs] save_model(model=Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                nume...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='shot_made_flag')),\n",
      "                ('fix_perfect', Remove_100(target='shot_made_flag')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False), model_name=Transformation Pipeline, prep_pipe_=Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                nume...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='shot_made_flag')),\n",
      "                ('fix_perfect', Remove_100(target='shot_made_flag')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False), verbose=False, kwargs={})\n",
      "INFO  [logs] Adding model into prep_pipe\n",
      "WARNI [logs] Only Model saved as it was a pipeline.\n",
      "INFO  [logs] Transformation Pipeline.pkl saved in current working directory\n",
      "INFO  [logs] Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                nume...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='shot_made_flag')),\n",
      "                ('fix_perfect', Remove_100(target='shot_made_flag')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False)\n",
      "INFO  [logs] save_model() successfully completed......................................\n",
      "INFO  [logs] SubProcess save_model() end ==================================\n",
      "INFO  [logs] create_model_container: 0\n",
      "INFO  [logs] master_model_container: 0\n",
      "INFO  [logs] display_container: 1\n",
      "INFO  [logs] Pipeline(memory=None,\n",
      "         steps=[('dtypes',\n",
      "                 DataTypes_Auto_infer(categorical_features=[],\n",
      "                                      display_types=False, features_todrop=[],\n",
      "                                      id_columns=[],\n",
      "                                      ml_usecase='classification',\n",
      "                                      numerical_features=[],\n",
      "                                      target='shot_made_flag',\n",
      "                                      time_features=[])),\n",
      "                ('imputer',\n",
      "                 Simple_Imputer(categorical_strategy='not_available',\n",
      "                                fill_value_categorical=None,\n",
      "                                fill_value_numerical=None,\n",
      "                                nume...\n",
      "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
      "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
      "                ('cluster_all', 'passthrough'),\n",
      "                ('dummy', Dummify(target='shot_made_flag')),\n",
      "                ('fix_perfect', Remove_100(target='shot_made_flag')),\n",
      "                ('clean_names', Clean_Colum_Names()),\n",
      "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
      "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
      "         verbose=False)\n",
      "INFO  [logs] setup() succesfully completed......................................\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [137]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# train/test\u001b[39;00m\n\u001b[0;32m     15\u001b[0m s \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39msetup(data \u001b[38;5;241m=\u001b[39m df_kobe_2p, \n\u001b[0;32m     16\u001b[0m              target \u001b[38;5;241m=\u001b[39m kobe_target_col,\n\u001b[0;32m     17\u001b[0m              train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m              verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     25\u001b[0m             )\n\u001b[1;32m---> 26\u001b[0m bestmodel \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[43mmodel_name\u001b[49m,cross_validation \u001b[38;5;241m=\u001b[39m cross_validation,probability_threshold\u001b[38;5;241m=\u001b[39mprobability_threshold)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#add_metric('logloss', 'Log Loss', log_loss, greater_is_better = False)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m bestmodel \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mcompare_models(include \u001b[38;5;241m=\u001b[39m models, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m,n_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "# COLOCAR RUN DE TREINAMENTO DE MODELOS\n",
    "# PARAMETROS: fold_strategy, fold, model_name, registered_model_name, cross_validation\n",
    "# METRICS: auto sklearn\n",
    "# ARTIFACTS: plots\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'Treinamento'):\n",
    "    \n",
    "    models = ['rf','lr']\n",
    "    probability_threshold = 0.5\n",
    "    cross_validation = True\n",
    "    fold_strategy = 'stratifiedkfold',\n",
    "    fold = 10\n",
    "\n",
    "    # train/test\n",
    "    s = pc.setup(data = df_kobe_2p, \n",
    "                 target = kobe_target_col,\n",
    "                 train_size=0.8,\n",
    "                 silent = True,\n",
    "                 fold_strategy = 'stratifiedkfold',\n",
    "                 fold = fold,\n",
    "                 log_experiment = True, \n",
    "                 experiment_name = experiment_name, \n",
    "                 log_plots = True,\n",
    "                 verbose=False\n",
    "                )\n",
    "    \n",
    "    add_metric('logloss', 'Log Loss', log_loss, greater_is_better = False)\n",
    "    bestmodels = pc.compare_models(include = models, sort='f1',n_select=2)\n",
    "    \n",
    "    # Log do run, e nao do modelo respectivo\n",
    "    classification_plots = [ 'auc','pr','confusion_matrix',\n",
    "    #                          'error', 'class_report', \n",
    "                            'threshold',\n",
    "                             'learning','vc','feature',\n",
    "                           ]\n",
    "    for plot_type in classification_plots:\n",
    "        print('=> Aplicando plot ', plot_type)\n",
    "        try:\n",
    "            artifact = pc.plot_model(bestmodels[0], plot=plot_type, save=True, use_train_data=False)\n",
    "            mlflow.log_artifact(artifact)\n",
    "        except:\n",
    "            print('=> Nao possivel plotar: ', plot_type )\n",
    "            continue\n",
    "\n",
    "    pred_holdout = pc.predict_model(bestmodels[0])\n",
    "    pred_holdout_sec = pc.predict_model(bestmodels[1])\n",
    "    mlflow.log_metrics({\"log loss Arvore\":  log_loss(ytest, pred_holdout['Label']),\n",
    "                       \"f1 Arvore\": f1_score(ytest, pred_holdout['Label'].astype(float)),\n",
    "                       })\n",
    "    \n",
    "    mlflow.log_metrics({\"log loss LR\":  log_loss(ytest, pred_holdout_sec['Label']),\n",
    "                       \"f1 LR\": f1_score(ytest, pred_holdout_sec['Label'].astype(float)),\n",
    "                       })\n",
    "    \n",
    "    pc.save_model(bestmodels[0], f'Data/Modeling/{registered_model_name}') \n",
    "    # Carrega novamente o pipeline + bestmode\n",
    "    model_pipe = pc.load_model(f'Data/Modeling/{registered_model_name}')\n",
    "\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4b246-b1a3-4ce7-925d-46e66c163528",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465224d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Artefatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3f274",
   "metadata": {},
   "source": [
    "# AUC\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/AUC.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/AUC.png >\n",
    "# Matriz de confusão\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Confusion%20Matrix.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Confusion%20Matrix.png>\n",
    "# Feature Importance\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Feature%20Importance.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Feature%20Importance.png>\n",
    "# Curva de aprendizado\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Learning%20Curve.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Learning%20Curve.png>\n",
    "# Precision Recall\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Precision%20Recall.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Precision%20Recall.png>\n",
    "# Threshold\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Threshold.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Threshold.png>\n",
    "# Threshold\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Validation%20Curve.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Validation%20Curve.png >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7713bf-2d98-4a2f-aaff-77bdff3df269",
   "metadata": {},
   "source": [
    "Pipeline para os Rastreamento dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO RASTREAMENTO\n",
    "\n",
    "MLFlow - É utilizado para a criação de APIs e a criação dos modelos desenvolvidos para o log, além disso é possivel utilizar através da API para outras bases\n",
    "\n",
    "PyCaret - É utilizado para buscar as configurações dos dados que foram registrados nas etapas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be995435-1185-4c2d-b9a1-4565ba6481ed",
   "metadata": {},
   "source": [
    "Servir Dados do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0bda104-d373-4485-aac2-6be1f029f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "#sqlite:///mlruns.db\n",
    "registered_model_name = registered_model_name\n",
    "model_version = -1 # recuperar a ultima versao\n",
    "nexamples = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb8b1ad7-5125-4e3c-b722-e651735a6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assinatura do Modelo Inferida pelo MLFlow\n",
    "model_features = list(df_kobe_3p.drop(kobe_target_col, axis=1).columns)\n",
    "inf_signature = infer_signature(df_kobe_3p[model_features], model_pipe.predict(df_kobe_3p))\n",
    "# Exemplo de entrada para o MLmodel\n",
    "input_example = {x: df_kobe_3p[x].values[:nexamples] for x in model_features}\n",
    "# Log do pipeline de modelagem do sklearn e registrar como uma nova versao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "570e6ab0-9fa7-4d3c-9d4b-a7f3d19539db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/01 11:56:38 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\CASSIO~1.COS\\AppData\\Local\\Temp\\tmpt7alnyr5\\model\\model.pkl, flavor: sklearn), fall back to return ['scikit-learn==0.23.2', 'cloudpickle==2.2.0']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'modelo_projeto' already exists. Creating a new version of this model...\n",
      "2022/10/01 11:56:39 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: modelo_projeto, version 3\n",
      "Created version '3' of model 'modelo_projeto'.\n"
     ]
    }
   ],
   "source": [
    "# Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "mlflow.sklearn.log_model(\n",
    "     sk_model=model_pipe,\n",
    "     artifact_path=\"sklearn-model\",\n",
    "     registered_model_name=registered_model_name,\n",
    "     signature = inf_signature,\n",
    "     input_example = input_example\n",
    " )\n",
    "# Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "client = MlflowClient()\n",
    "if model_version == -1:\n",
    "    model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "# Registrar o modelo como staging\n",
    "client.transition_model_version_stage(\n",
    "     name=registered_model_name,\n",
    "     version=model_version, # Verificar com usuario qual versao\n",
    "     stage=\"Staging\"\n",
    ")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "882acbcb-a115-4462-8c94-14c56d84eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py:2322: FutureWarning: `--no-conda` is deprecated and will be removed in a future MLflow release. Use `--env-manager=local` instead.\n",
      "  value = self.callback(ctx, self, value)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\Scripts\\mlflow-script.py\", line 10, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\models\\cli.py\", line 68, in serve\n",
      "    return _get_flavor_backend(\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\models\\cli.py\", line 224, in _get_flavor_backend\n",
      "    underlying_model_uri = ModelsArtifactRepository.get_underlying_uri(model_uri)\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\artifact\\models_artifact_repo.py\", line 69, in get_underlying_uri\n",
      "    (name, version) = get_model_name_and_version(client, uri)\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\artifact\\utils\\models.py\", line 74, in get_model_name_and_version\n",
      "    return model_name, str(_get_latest_model_version(client, model_name, model_stage))\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\artifact\\utils\\models.py\", line 28, in _get_latest_model_version\n",
      "    latest = client.get_latest_versions(name, None if stage is None else [stage])\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\tracking\\client.py\", line 2178, in get_latest_versions\n",
      "    return self._get_registry_client().get_latest_versions(name, stages)\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\client.py\", line 149, in get_latest_versions\n",
      "    return self.store.get_latest_versions(name, stages)\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\model_registry\\sqlalchemy_store.py\", line 549, in get_latest_versions\n",
      "    sql_registered_model = self._get_registered_model(session, name)\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\store\\model_registry\\sqlalchemy_store.py\", line 216, in _get_registered_model\n",
      "    raise MlflowException(\n",
      "mlflow.exceptions.MlflowException: Registered Model with name=modelo_projeto_kobe not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'sqlite:///mlruns.db'\n",
    "\n",
    "!mlflow models serve -m \"models:/modelo_projeto_kobe/Staging\" --no-conda -p 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3395dbf0-75f8-48a5-a7f6-0e9d6cfe1e3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002AC2ABACBB0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000002AC2ABACBB0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002AC2ABACBB0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      7\u001b[0m http_data \u001b[38;5;241m=\u001b[39m data_operation\u001b[38;5;241m.\u001b[39mdrop(kobe_target_col,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m data_operation\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperation_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(r\u001b[38;5;241m.\u001b[39mtext)\u001b[38;5;241m.\u001b[39mvalues[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m data_operation\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Modeling/modelo_kobe_operacao.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002AC2ABACBB0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "host = 'localhost'\n",
    "port = '5000'\n",
    "url = f'http://127.0.0.1'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "http_data = data_operation.drop(kobe_target_col,axis=1).to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)\n",
    "data_operation.loc[:, 'operation_label'] = pd.read_json(r.text).values[:,0]\n",
    "data_operation.to_parquet('Data/Modeling/modelo_kobe_operacao.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290adcd-3efd-4908-a583-6ae2c80319f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(data_operation[kobe_target_col], data_operation['operation_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71d42c-146c-48ca-a18e-0a0549f4e383",
   "metadata": {},
   "source": [
    "Consumir o Serviço do Kobe Bryant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832fc9c-d350-4abf-beba-9f966c22f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/invocations -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"lat\\\", \\\"lon\\\", \\\"minutes_remaining\\\", \\\"period\\\",\\\"playoffs\\\",\\\"shot_distance\\\"],\\\"data\\\":[[35.9913,-120.3178,8,4,0,7],[33.9703,-118.2908,11,3,0,7]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ffc2c7-dfdc-40ee-8e15-bfdf6b678bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_data = df_kobe_3p.drop(kobe_target_col,axis=1).to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9216f9-fe6e-4d75-934b-4089184ee2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kobe_3p.loc[:, 'operation_label'] = pd.read_json(r.text).values[:,0]\n",
    "\n",
    "print(metrics.classification_report(df_kobe_3p[kobe_target_col], df_kobe_3p['operation_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af77b6-a952-4f3e-89fc-20ebf9f84cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kobe_3p[kobe_target_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5866ef2-21bf-4dba-ac21-d025a09ec8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kobe_3p['operation_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a68ec-e8d1-47fe-b097-e2e673d8dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "host = 'localhost'\n",
    "port = '5000'\n",
    "url = f'http://{host}:{port}/invocations'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "http_data = data_operation.drop(kobe_target_col,axis=1).to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725d896-1259-4127-bc2a-22f8ec8d717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/invocations -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"lat\\\", \\\"lon\\\", \\\"minutes_remaining\\\", \\\"period\\\",\\\"playoffs\\\",\\\"shot_distance\\\"],\\\"data\\\":[[35.9913,-120.3178,8,4,0,7],[33.9703,-118.2908,11,3,0,7]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177b962-f569-4e26-ae48-477c90a55880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kobe_3p['operation_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbeb14-1053-4b08-a034-2f82e313e103",
   "metadata": {},
   "source": [
    "Pipeline para os Monitoramento dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO MONITORAMENTO\n",
    "\n",
    "MLFlow - É utilizado para registrar os experimentos e treinamentos da base dos dados para comparar na aprovação dos dados e recuperar os dados do modelo. Além de gravar os dados colocados no modelo\n",
    "\n",
    "PyCaret - Auxilia para fazer a predição dos modelos resgatados pelo Mlflow além das configurações utilizadas nos modelos.\n",
    "\n",
    "Scikit-Learn - É utilizado para fazer os calculos das métricas dos modelos selecionados\n",
    "\n",
    "Aprovação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21227b-14cf-42d4-bb45-5707b78ac6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_accuracy = 0.5\n",
    "model_version = -1 # recuperar a ultima versao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3094c-0407-4ad1-a266-ae6b6b330f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCAR RUN APROVACAO DE MODELO\n",
    "# PARAMETROS: min_accuracy\n",
    "# METRICS: new_version, accuracy\n",
    "# ARTIFACTS: None\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'AprovacaoModelo'):\n",
    "    pred_holdout = pc.predict_model(bestmodel[0])\n",
    "    acc = metrics.accuracy_score(pred_holdout[kobe_target_col], pred_holdout['Label'])\n",
    "    if acc > min_precision:\n",
    "        print(f'=> Aceito o modelo com precisão {acc} (min: {min_accuracy})')\n",
    "        pred_holdout.to_parquet('../Data/Processed/modelo_kobe_teste.parquet')\n",
    "        # Assinatura do Modelo Inferida pelo MLFlow\n",
    "        model_features = list(df_kobe.drop(kobe_target_col, axis=1).columns)\n",
    "        inf_signature = infer_signature(df_kobe[model_features], model_pipe.predict(df_kobe))\n",
    "        # Exemplo de entrada para o MLmodel\n",
    "        input_example = {x: df_kobe[x].values[:nexamples] for x in model_features}\n",
    "        # Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_pipe,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            registered_model_name=registered_model_name,\n",
    "            signature = inf_signature,\n",
    "            input_example = input_example\n",
    "        )\n",
    "        # Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "        client = MlflowClient()\n",
    "        if model_version == -1:\n",
    "            model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "        # Registrar o modelo como staging\n",
    "        client.transition_model_version_stage(\n",
    "            name=registered_model_name,\n",
    "            version=model_version, # Verificar com usuario qual versao\n",
    "            stage=\"Staging\"\n",
    "        )\n",
    "    else:\n",
    "        print(f'=> Rejeitado o modelo com precisão {acc} (min: {min_accuracy})')\n",
    "\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"precisao_minima\", min_accuracy)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"new_version\", model_version)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7edecf-dda6-4e12-922b-3ac829abd319",
   "metadata": {},
   "source": [
    "Revalidacao de Amostras para Monitoramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a586d1-3e67-4cb6-8914-c5634f255c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCAR RUN REVALIDACAO\n",
    "# PARAMETROS: min_samples_control\n",
    "# METRICS: matriz de confusao\n",
    "# ARTIFACTS:\n",
    "\n",
    "\n",
    "# Utilizacao da amostra de controle, que teria sido reavaliada por especialistas\n",
    "min_samples_control = 150\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'RevalidacaoOperacao'):\n",
    "\n",
    "    data_operation = pd.read_parquet('../Data/Modeling/modelo_kobe_operacao.parquet')\n",
    "\n",
    "    data_control = data_operation.sample(min_samples_control, random_state=SEED)\n",
    "    data_control.to_parquet('../Data/Processed/modelo_kobe_controle.parquet')\n",
    "\n",
    "    print('== DADOS DE CONTROLE ==')\n",
    "    print(metrics.classification_report(data_control[kobe_target_col], data_control['operation_label']))\n",
    "    \n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"min_samples_control\", min_samples_control)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    cm = metrics.confusion_matrix(data_control[kobe_target_col], data_control['operation_label'])\n",
    "    specificity = cm[0,0] / cm.sum(axis=1)[0]\n",
    "    sensibility = cm[1,1] / cm.sum(axis=1)[1]\n",
    "    precision   = cm[1,1] / cm.sum(axis=0)[1]\n",
    "    mlflow.log_metric(\"Especificidade\", specificity)\n",
    "    mlflow.log_metric(\"Sensibilidade\", sensibility)\n",
    "    mlflow.log_metric(\"Precisao\", precision)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571da333-b3f2-4648-9349-29a65b83cf4e",
   "metadata": {},
   "source": [
    "Alarme de Desvio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae3250-3097-4c4d-9d68-c6b22a8cdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset matplotlib\n",
    "\n",
    "mpl.rcParams.update(inline_rc)\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "mpl.rc('font', **font)\n",
    "lines = {'linewidth' : 3}\n",
    "mpl.rc('lines', **lines)\n",
    "\n",
    "def data_drift_alarm(var_name, dev_data, data_test, data_control):    \n",
    "    sn.kdeplot(dev_data[var_name], label='Desenvolvimento')\n",
    "    sn.kdeplot(data_test[var_name], label='Teste')\n",
    "    sn.kdeplot(data_control[var_name], label='Monitoramento')\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(f'Distribuição Variável {var_name}')\n",
    "    plt.ylabel('Distancia')\n",
    "    plt.xlabel(f'Unidade de {var_name}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95bd71-4811-4858-ac19-04d01f1bdcc7",
   "metadata": {},
   "source": [
    "Alarme de Retreinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7950dd9-e894-4d19-9203-04121a25425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alarm(data_monitoring, testset, min_eff_alarm):\n",
    "    cm = metrics.confusion_matrix(data_monitoring[kobe_target_col], data_monitoring['operation_label'])\n",
    "    specificity_m = cm[0,0] / cm.sum(axis=1)[0]\n",
    "    sensibility_m = cm[1,1] / cm.sum(axis=1)[1]\n",
    "    precision_m   = cm[1,1] / cm.sum(axis=0)[1]\n",
    "\n",
    "    cm = metrics.confusion_matrix(testset[kobe_target_col], testset['Label'])\n",
    "    specificity_t = cm[0,0] / cm.sum(axis=1)[0]\n",
    "    sensibility_t = cm[1,1] / cm.sum(axis=1)[1]\n",
    "    precision_t   = cm[1,1] / cm.sum(axis=0)[1]\n",
    "\n",
    "    retrain = False\n",
    "    for name, metric_m, metric_t in zip(['especificidade', 'sensibilidade', 'precisao'],\n",
    "                                        [specificity_m, sensibility_m, precision_m],\n",
    "                                        [specificity_t, sensibility_t, precision_t]):\n",
    "        \n",
    "        print(f'\\t=> {name} de teste {metric_t} e de controle {metric_m}')\n",
    "        if (metric_t-metric_m)/metric_t > min_eff_alarm:\n",
    "            print(f'\\t=> MODELO OPERANDO FORA DO ESPERADO')\n",
    "            retrain = True\n",
    "        else:\n",
    "            print(f'\\t=> MODELO OPERANDO DENTRO DO ESPERADO')\n",
    "           \n",
    "        \n",
    "    return (retrain, [specificity_m, sensibility_m, precision_m],\n",
    "                                        [specificity_t, sensibility_t, precision_t] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4601f96-518d-4a0b-8356-d47ea85ac9b1",
   "metadata": {},
   "source": [
    "Monitoramento Base Operação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde9242-d73a-4cb5-94f1-005de0c053e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCAR RUN MONITORAMENTO OPERACAO\n",
    "# PARAMETROS: min_eff_alarm\n",
    "# METRICS: metricas avaliadas e de referencia\n",
    "# ARTIFACTS:\n",
    "\n",
    "print('== ALARME DE RETREINAMENTO - BASE CONTROLE ==')\n",
    "# 10% de desvio aceitavel na metrica. Deve ser estimado pelo conjunto de validacao cruzada. \n",
    "min_eff_alarm = 0.1 \n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'MonitoramentoOperacao'):\n",
    "    data_control = pd.read_parquet('../Data/Processed/modelo_kobe_controle.parquet')\n",
    "    \n",
    "    (retrain, [specificity_m, sensibility_m, precision_m],\n",
    "              [specificity_t, sensibility_t, precision_t] ) = alarm(data_control, pred_holdout, min_eff_alarm)\n",
    "    if retrain:\n",
    "        print('==> RETREINAMENTO NECESSARIO')\n",
    "    else:\n",
    "        print('==> RETREINAMENTO NAO NECESSARIO')\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"min_eff_alarm\", min_eff_alarm)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"Alarme Retreino\", float(retrain))\n",
    "    mlflow.log_metric(\"Especificidade Controle\", specificity_m)\n",
    "    mlflow.log_metric(\"Sensibilidade Controle\", sensibility_m)\n",
    "    mlflow.log_metric(\"Precisao Controle\", precision_m)\n",
    "    mlflow.log_metric(\"Especificidade Teste\", specificity_t)\n",
    "    mlflow.log_metric(\"Sensibilidade Teste\", sensibility_t)\n",
    "    mlflow.log_metric(\"Precisao Teste\", precision_t)\n",
    "    \n",
    "    # LOG ARTEFATO\n",
    "    var_name = 'shot_distance' # 'alcohol'\n",
    "    data_drift_alarm(var_name, df_kobe, pred_holdout, data_control)\n",
    "    plot_path = f'monitor_datadrift_{var_name}.png'\n",
    "    plt.savefig(plot_path)\n",
    "    mlflow.log_artifact(plot_path)\n",
    "    \n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91022008-fbf6-48dd-b8b3-a3fb6bafd064",
   "metadata": {},
   "source": [
    "Pipeline para a Atualização dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NA ATUALIZAÇÃO\n",
    "\n",
    "MLFlow - É utilizado para a criação de APIs e a criação dos modelos desenvolvidos para o log, além disso é possivel utilizar através da API para outras bases\n",
    "\n",
    "PyCaret - Criação de artefatos e grava parametros e metricas\n",
    "\n",
    "Scikit-Learn - Faz o carregamento do modelo dos dados gravados no Mlflow\n",
    "\n",
    "Monitoramento Base de Novidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae6006-8d6d-4625-b987-ca876dcc54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCAR RUN MONITORAMENTO NOVIDADE\n",
    "# PARAMETROS: min_eff_alarm\n",
    "# METRICS: metricas avaliadas e de referencia\n",
    "# ARTIFACTS:\n",
    "\n",
    "print('== ALARME DE RETREINAMENTO - BASE NOVIDADE ==')\n",
    "# 10% de desvio aceitavel na metrica. Deve ser estimado pelo conjunto de validacao cruzada. \n",
    "min_eff_alarm = 0.1 \n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'MonitoramentoNovidade'):\n",
    "\n",
    "    model_uri = f\"models:/modelo_kobe/Staging\"\n",
    "    loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "    data_novelty = pd.read_parquet('../Data/Processed/base_kobe_novidade.parquet')\n",
    "    data_novelty.loc[:, 'operation_label'] = loaded_model.predict(data_novelty)\n",
    "    \n",
    "    (retrain, [specificity_m, sensibility_m, precision_m],\n",
    "              [specificity_t, sensibility_t, precision_t] ) = alarm(data_novelty, pred_holdout, min_eff_alarm)\n",
    "    if retrain:\n",
    "        print('==> RETREINAMENTO NECESSARIO')\n",
    "    else:\n",
    "        print('==> RETREINAMENTO NAO NECESSARIO')\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"min_eff_alarm\", min_eff_alarm)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"Alarme Retreino\", float(retrain))\n",
    "    mlflow.log_metric(\"Especificidade Controle\", specificity_m)\n",
    "    mlflow.log_metric(\"Sensibilidade Controle\", sensibility_m)\n",
    "    mlflow.log_metric(\"Precisao Controle\", precision_m)\n",
    "    mlflow.log_metric(\"Especificidade Teste\", specificity_t)\n",
    "    mlflow.log_metric(\"Sensibilidade Teste\", sensibility_t)\n",
    "    mlflow.log_metric(\"Precisao Teste\", precision_t)\n",
    "    # LOG ARTEFATO\n",
    "    var_name = 'shot_distance' # 'alcohol'\n",
    "    data_drift_alarm(var_name, df_kobe, pred_holdout, data_novelty)\n",
    "    plot_path = f'novidade_datadrift_{var_name}.png'\n",
    "    plt.savefig(plot_path)\n",
    "    mlflow.log_artifact(plot_path)\n",
    "\n",
    "mlflow.end_run()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e633274-749c-45f0-88e9-744b43a49752",
   "metadata": {},
   "source": [
    "Pipeline para o Provisionamento dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO PROVISIONAMENTO\n",
    "\n",
    "MLFlow - É utilizado para a transição do modelo para a produção\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806339b3-b2df-47ef-a07f-c34578770bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "mlflow.sklearn.log_model(\n",
    "     sk_model=model_pipe,\n",
    "     artifact_path=\"sklearn-model\",\n",
    "     registered_model_name=registered_model_name,\n",
    "     signature = inf_signature,\n",
    "     input_example = input_example\n",
    " )\n",
    "# Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "client = MlflowClient()\n",
    "if model_version == -1:\n",
    "    model_version = client.get_latest_versions(registered_model_name).version\n",
    "# Registrar o modelo como staging\n",
    "client.transition_model_version_stage(\n",
    "     name=registered_model_name,\n",
    "     version=client.get_latest_versions(registered_model_name).version, # Verificar com usuario qual versao\n",
    "     stage=\"Production\"\n",
    ")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045ae28-ba65-4545-8da0-3c50bb933343",
   "metadata": {},
   "source": [
    "Questão 3) O objetivo de uma pipeline é automatizar o processo de entrega de software em produção de forma rápida, ao mesmo tempo garantindo sua estabilidade, qualidade e resiliência\n",
    "\n",
    "Questão 4) MLflow é uma ferramenta de ciclo de vida de aprendizado de máquina de código aberto, que facilita o gerenciamento do fluxo de trabalho para treinamento, rastreamento e produção de modelos de machine learning. Ele foi organizado para funcionar com as bibliotecas e estruturas de aprendizado de máquina mais recentes e utilizadas no mercado atualmente.\n",
    "\n",
    "O Streamlit é uma biblioteca Python de código aberto que auxilia equipes de aprendizado de máquina e ciência de dados a criarem e compartilharem aplicativos Web personalizados sem a necessidade de conhecer ferramentas de front-end ou de deploy de aplicações\n",
    "\n",
    "PyCaret é uma biblioteca do Python que permite que você faça todo o ciclo da criação de um modelo de Machine Learning com poucas linhas de código.\n",
    "\n",
    "O scikit-learn é uma biblioteca da linguagem Python desenvolvida especificamente para aplicação prática de machine learning.\n",
    "\n",
    "Questão 8)\n",
    "a. O modelo não é aderente a nova base, pois já no treinamento na base de 2 pontos ele não apresentou uma boa preformance. Além disso, outras variaveis ajudam no desenpenho do modelo. As variáveis latitude e longitude representam a posição em que foi jogada a bola, quanto mais longe mais dificil é acertar a cesta.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
