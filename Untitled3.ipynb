{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b643d84-f913-4a05-8b5c-af040428bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing, metrics, model_selection\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from pycaret.classification import *\n",
    "import pycaret.classification as pc\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "if 'inline_rc' not in dir():\n",
    "    inline_rc = dict(mpl.rcParams)\n",
    "\n",
    "SEED = 7\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c31c2c-bacc-4ee3-a77c-e3b5d52ad857",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update(inline_rc)\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 15}\n",
    "mpl.rc('font', **font)\n",
    "lines = {'linewidth' : 2}\n",
    "mpl.rc('lines', **lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b8f4c5-87f1-4fe7-a35f-256da4efa79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_name = 'modelo_projeto_kobe'\n",
    "min_precision = 0.75\n",
    "model_version = -1 # recuperar a ultima versao\n",
    "nexamples = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ded5b-e794-470e-8460-62fa8b362494",
   "metadata": {},
   "source": [
    "Diagrama do Pipeline do Projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e5b37-5ba4-4697-8899-a42c3867d8ce",
   "metadata": {},
   "source": [
    "https://github.com/cassiobcosta/Kobe/blob/main/Apresenta%C3%A7%C3%A3o1.jpg\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Apresenta%C3%A7%C3%A3o1.jpg >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e781adc1",
   "metadata": {},
   "source": [
    "Neste momento torna-se necessário variar os pipelines de forma que poderemos aproveitar os dados estruturados para avaliar e verificar se os experimentos foram bem feitos e se pode haver uma melhoria nos dados descritos.\n",
    "\n",
    "Para isso é preciso criar um pipeline para ter um referencial dos modelos criados e guardar os dados dos modelos. Podemos ter os artefatos,métricas e parametros utilizados e testar diferentes modelos para achar o melhor modelo para validar os dados e utilizá-los da melhor maneira.\n",
    "\n",
    "É possível através deste pipeline separarmos o que será utilizado em desenvolvimento e em seguida colocar em produção os dados utilizados.\n",
    "\n",
    "Após a validação dos modelos colocados em desenvolvimento, pode ser colocado o modelo em produção para que possa ser utilizado nas APIs selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbd761-3906-4b7e-9aa1-ed33297b85af",
   "metadata": {},
   "source": [
    "Inicio dos Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "780feb34-95d1-45df-99fd-c7c8e71bfcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usar o sqlite como repositorio\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "#sqlite:///mlruns.db\n",
    "experiment_name = 'Projeto Kobe Bryant'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13494f14-1148-4057-9d77-8aeaf104cb7d",
   "metadata": {},
   "source": [
    "Pipeline para a Preparação dos Dados Kobe Bryant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea35fe78-23dd-44b8-8d9c-359e2c8e0e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/20 22:56:12 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Bases de Dados **\n",
      "xtrain (16228, 7)\n",
      "data_operation (4057, 7)\n",
      "Columns: Index(['lat', 'lon', 'minutes_remaining', 'period', 'playoffs',\n",
      "       'shot_distance', 'shot_made_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# COLOCAR RUN DE LEITURA DE DADOS\n",
    "# PARAMETROS: top_features,\n",
    "# METRICS: SHAPE de cada base de dados\n",
    "# ARTIFACTS: nenhum\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "    df_kobe = pd.read_csv('kobe_dataset.csv',sep=',')\n",
    "    kobe_target_col = 'shot_made_flag'\n",
    "    df_kobe_2p = df_kobe[df_kobe['shot_type'] == '2PT Field Goal']\n",
    "    df_kobe_3p = df_kobe[df_kobe['shot_type'] == '3PT Field Goal']\n",
    "    df_kobe_2p = df_kobe_2p[['lat','lon','minutes_remaining','period', 'playoffs','shot_distance','shot_made_flag']]\n",
    "    df_kobe_3p = df_kobe_3p[['lat','lon','minutes_remaining','period', 'playoffs','shot_distance','shot_made_flag']]\n",
    "    df_kobe_2p = df_kobe_2p.dropna()\n",
    "    df_kobe_3p = df_kobe_3p.dropna()\n",
    "    test_size = 0.2\n",
    "    \n",
    "    # Separar parte para compor a base de operacao\n",
    "    xtrain, data_operation, ytrain, ytest = model_selection.train_test_split(df_kobe_2p, \n",
    "                                                                            df_kobe_2p[kobe_target_col],\n",
    "                                                                            test_size=test_size)\n",
    "    \n",
    "    data_novelty = df_kobe_3p.copy()\n",
    "\n",
    "    xtrain.to_parquet('Data/Processed/data_filtered.parquet')\n",
    "    data_operation.to_parquet('Data/Processed/base_8020.parquet')\n",
    "    data_novelty.to_parquet('Data/Processed/base_kobe_novidade.parquet')\n",
    "\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"test_size\", test_size)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"data_dev\", df_kobe_2p.shape[0])\n",
    "    mlflow.log_metric(\"data_operation\", data_operation.shape[0])\n",
    "   \n",
    "    \n",
    "mlflow.end_run()\n",
    "\n",
    "print('** Bases de Dados **')\n",
    "print(f'xtrain {xtrain.shape}')\n",
    "print(f'data_operation {data_operation.shape}')\n",
    "print(f'Columns: {df_kobe_2p.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b38289c2-8650-421e-a961-b0e127d00a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2PT Field Goal    24271\n",
       "3PT Field Goal     6426\n",
       "Name: shot_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kobe['shot_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d412c4b-5e23-4caf-842a-3ef4b64ab00e",
   "metadata": {},
   "source": [
    "Pipeline para os Treinamentos dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO TREINAMENTO\n",
    "\n",
    "Streamlit - Pode ser utilizado para a criação dos Dashboards\n",
    "\n",
    "MLFlow - É utilizado para registrar os experimentos e treinamentos da base dos dados além de salvar artefatos, parametros e métricas\n",
    "\n",
    "PyCaret - Verifica o melhor modelo da base através dos parametros a serem utilizados, gera os artefatos e além das bases treinados\n",
    "\n",
    "Scikit-Learn - É utiliado para calcular as métricas geradas no treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048143d-732a-4866-b4e1-41115ce64ceb",
   "metadata": {},
   "source": [
    "Pipeline para o Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91fd2f92-e7cb-4e10-b227-0ccc6179f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_664d4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_664d4_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_664d4_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_664d4_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_664d4_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_664d4_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_664d4_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_664d4_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_664d4_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_664d4_level0_col8\" class=\"col_heading level0 col8\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_664d4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_664d4_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_664d4_row0_col1\" class=\"data row0 col1\" >0.5556</td>\n",
       "      <td id=\"T_664d4_row0_col2\" class=\"data row0 col2\" >0.5622</td>\n",
       "      <td id=\"T_664d4_row0_col3\" class=\"data row0 col3\" >0.5284</td>\n",
       "      <td id=\"T_664d4_row0_col4\" class=\"data row0 col4\" >0.5392</td>\n",
       "      <td id=\"T_664d4_row0_col5\" class=\"data row0 col5\" >0.5337</td>\n",
       "      <td id=\"T_664d4_row0_col6\" class=\"data row0 col6\" >0.1093</td>\n",
       "      <td id=\"T_664d4_row0_col7\" class=\"data row0 col7\" >0.1093</td>\n",
       "      <td id=\"T_664d4_row0_col8\" class=\"data row0 col8\" >15.3498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e093d264c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_37cd7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_37cd7_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_37cd7_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_37cd7_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_37cd7_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_37cd7_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_37cd7_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_37cd7_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_37cd7_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_37cd7_level0_col8\" class=\"col_heading level0 col8\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_37cd7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_37cd7_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_37cd7_row0_col1\" class=\"data row0 col1\" >0.5817</td>\n",
       "      <td id=\"T_37cd7_row0_col2\" class=\"data row0 col2\" >0.5921</td>\n",
       "      <td id=\"T_37cd7_row0_col3\" class=\"data row0 col3\" >0.4747</td>\n",
       "      <td id=\"T_37cd7_row0_col4\" class=\"data row0 col4\" >0.5801</td>\n",
       "      <td id=\"T_37cd7_row0_col5\" class=\"data row0 col5\" >0.5221</td>\n",
       "      <td id=\"T_37cd7_row0_col6\" class=\"data row0 col6\" >0.1568</td>\n",
       "      <td id=\"T_37cd7_row0_col7\" class=\"data row0 col7\" >0.1593</td>\n",
       "      <td id=\"T_37cd7_row0_col8\" class=\"data row0 col8\" >14.4473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e093d3fd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "# COLOCAR RUN DE TREINAMENTO DE MODELOS\n",
    "# PARAMETROS: fold_strategy, fold, model_name, registered_model_name, cross_validation\n",
    "# METRICS: auto sklearn\n",
    "# ARTIFACTS: plots\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'Treinamento'):\n",
    "    \n",
    "    models = ['rf','lr']\n",
    "    probability_threshold = 0.5\n",
    "    cross_validation = True\n",
    "    fold_strategy = 'stratifiedkfold',\n",
    "    fold = 10\n",
    "\n",
    "    # train/test\n",
    "    s = pc.setup(data = df_kobe_2p, \n",
    "                 target = kobe_target_col,\n",
    "                 train_size=0.8,\n",
    "                 silent = True,\n",
    "                 fold_strategy = 'stratifiedkfold',\n",
    "                 fold = fold,\n",
    "                 log_experiment = True, \n",
    "                 experiment_name = experiment_name, \n",
    "                 log_plots = True,\n",
    "                 verbose=False\n",
    "                )\n",
    "    \n",
    "    add_metric('logloss', 'Log Loss', log_loss, greater_is_better = False)\n",
    "    bestmodels = pc.compare_models(include = models, sort='f1',n_select=2)\n",
    "    \n",
    "    # Log do run, e nao do modelo respectivo\n",
    "    classification_plots = [ 'auc','pr','confusion_matrix',\n",
    "    #                          'error', 'class_report', \n",
    "                            'threshold',\n",
    "                             'learning','vc','feature',\n",
    "                           ]\n",
    "    for plot_type in classification_plots:\n",
    "        print('=> Aplicando plot ', plot_type)\n",
    "        try:\n",
    "            artifact = pc.plot_model(bestmodels[0], plot=plot_type, save=True, use_train_data=False)\n",
    "            mlflow.log_artifact(artifact)\n",
    "        except:\n",
    "            print('=> Nao possivel plotar: ', plot_type )\n",
    "            continue\n",
    "\n",
    "    pred_holdout = pc.predict_model(bestmodels[0])\n",
    "    pred_holdout_sec = pc.predict_model(bestmodels[1])\n",
    "    mlflow.log_metrics({\"log loss Arvore\":  log_loss(ytest, pred_holdout['Label']),\n",
    "                       \"f1 Arvore\": f1_score(ytest, pred_holdout['Label'].astype(float)),\n",
    "                       })\n",
    "    \n",
    "    mlflow.log_metrics({\"log loss LR\":  log_loss(ytest, pred_holdout_sec['Label']),\n",
    "                       \"f1 LR\": f1_score(ytest, pred_holdout_sec['Label'].astype(float)),\n",
    "                       })\n",
    "    \n",
    "    pc.save_model(bestmodels[0], f'Data/Modeling/{registered_model_name}') \n",
    "    # Carrega novamente o pipeline + bestmode\n",
    "    model_pipe = pc.load_model(f'Data/Modeling/{registered_model_name}')\n",
    "\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f454e5-2c78-428c-81d8-79b2f18f2953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=5488, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465224d",
   "metadata": {},
   "source": [
    "# Artefatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3f274",
   "metadata": {},
   "source": [
    "# AUC\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/AUC.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/AUC.png >\n",
    "# Matriz de confusão\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Confusion%20Matrix.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Confusion%20Matrix.png>\n",
    "# Feature Importance\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Feature%20Importance.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Feature%20Importance.png>\n",
    "# Curva de aprendizado\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Learning%20Curve.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Learning%20Curve.png>\n",
    "# Precision Recall\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Precision%20Recall.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Precision%20Recall.png>\n",
    "# Threshold\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Threshold.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Threshold.png>\n",
    "# Threshold\n",
    "https://github.com/cassiobcosta/Kobe/blob/main/Validation%20Curve.png\n",
    "<img src = https://github.com/cassiobcosta/Kobe/blob/main/Validation%20Curve.png >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7713bf-2d98-4a2f-aaff-77bdff3df269",
   "metadata": {},
   "source": [
    "Pipeline para os Rastreamento dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO RASTREAMENTO\n",
    "\n",
    "MLFlow - É utilizado para a criação de APIs e a criação dos modelos desenvolvidos para o log, além disso é possivel utilizar através da API para outras bases\n",
    "\n",
    "PyCaret - É utilizado para buscar as configurações dos dados que foram registrados nas etapas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be995435-1185-4c2d-b9a1-4565ba6481ed",
   "metadata": {},
   "source": [
    "Servir Dados do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0bda104-d373-4485-aac2-6be1f029f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "registered_model_name = 'modelo_projeto'\n",
    "model_version = -1 # recuperar a ultima versao\n",
    "nexamples = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8b1ad7-5125-4e3c-b722-e651735a6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assinatura do Modelo Inferida pelo MLFlow\n",
    "model_features = list(df_kobe_2p.drop(kobe_target_col, axis=1).columns)\n",
    "inf_signature = infer_signature(df_kobe_2p[model_features], model_pipe.predict(df_kobe_2p))\n",
    "# Exemplo de entrada para o MLmodel\n",
    "input_example = {x: df_kobe_2p[x].values[:nexamples] for x in model_features}\n",
    "# Log do pipeline de modelagem do sklearn e registrar como uma nova versao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "570e6ab0-9fa7-4d3c-9d4b-a7f3d19539db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/20 22:57:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\CASSIO~1.COS\\AppData\\Local\\Temp\\tmpknj6gzqr\\model\\model.pkl, flavor: sklearn), fall back to return ['scikit-learn==0.23.2', 'cloudpickle==2.2.0']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'modelo_projeto' already exists. Creating a new version of this model...\n",
      "2022/09/20 22:57:52 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: modelo_projeto, version 3\n",
      "Created version '3' of model 'modelo_projeto'.\n"
     ]
    }
   ],
   "source": [
    "# Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "mlflow.sklearn.log_model(\n",
    "     sk_model=model_pipe,\n",
    "     artifact_path=\"sklearn-model\",\n",
    "     registered_model_name=registered_model_name,\n",
    "     signature = inf_signature,\n",
    "     input_example = input_example\n",
    " )\n",
    "# Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "client = MlflowClient()\n",
    "if model_version == -1:\n",
    "    model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "# Registrar o modelo como staging\n",
    "client.transition_model_version_stage(\n",
    "     name=registered_model_name,\n",
    "     version=model_version, # Verificar com usuario qual versao\n",
    "     stage=\"Staging\"\n",
    ")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "882acbcb-a115-4462-8c94-14c56d84eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py:2322: FutureWarning: `--no-conda` is deprecated and will be removed in a future MLflow release. Use `--env-manager=local` instead.\n",
      "  value = self.callback(ctx, self, value)\n",
      "2022/09/20 22:57:56 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n",
      "2022/09/20 22:57:56 INFO mlflow.pyfunc.backend: === Running command 'waitress-serve --host=127.0.0.1 --port=5002 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "Error: Bad module 'mlflow.pyfunc.scoring_server.wsgi'\n",
      "\n",
      "Usage:\n",
      "\n",
      "    waitress-serve [OPTS] MODULE:OBJECT\n",
      "\n",
      "Standard options:\n",
      "\n",
      "    --help\n",
      "        Show this information.\n",
      "\n",
      "    --call\n",
      "        Call the given object to get the WSGI application.\n",
      "\n",
      "    --host=ADDR\n",
      "        Hostname or IP address on which to listen, default is '0.0.0.0',\n",
      "        which means \"all IP addresses on this host\".\n",
      "\n",
      "        Note: May not be used together with --listen\n",
      "\n",
      "    --port=PORT\n",
      "        TCP port on which to listen, default is '8080'\n",
      "\n",
      "        Note: May not be used together with --listen\n",
      "\n",
      "    --listen=ip:port\n",
      "        Tell waitress to listen on an ip port combination.\n",
      "\n",
      "        Example:\n",
      "\n",
      "            --listen=127.0.0.1:8080\n",
      "            --listen=[::1]:8080\n",
      "            --listen=*:8080\n",
      "\n",
      "        This option may be used multiple times to listen on multiple sockets.\n",
      "        A wildcard for the hostname is also supported and will bind to both\n",
      "        IPv4/IPv6 depending on whether they are enabled or disabled.\n",
      "\n",
      "    --[no-]ipv4\n",
      "        Toggle on/off IPv4 support.\n",
      "\n",
      "        Example:\n",
      "\n",
      "            --no-ipv4\n",
      "\n",
      "        This will disable IPv4 socket support. This affects wildcard matching\n",
      "        when generating the list of sockets.\n",
      "\n",
      "    --[no-]ipv6\n",
      "        Toggle on/off IPv6 support.\n",
      "\n",
      "        Example:\n",
      "\n",
      "            --no-ipv6\n",
      "\n",
      "        This will turn on IPv6 socket support. This affects wildcard matching\n",
      "        when generating a list of sockets.\n",
      "\n",
      "    --unix-socket=PATH\n",
      "        Path of Unix socket. If a socket path is specified, a Unix domain\n",
      "        socket is made instead of the usual inet domain socket.\n",
      "\n",
      "        Not available on Windows.\n",
      "\n",
      "    --unix-socket-perms=PERMS\n",
      "        Octal permissions to use for the Unix domain socket, default is\n",
      "        '600'.\n",
      "\n",
      "    --url-scheme=STR\n",
      "        Default wsgi.url_scheme value, default is 'http'.\n",
      "\n",
      "    --url-prefix=STR\n",
      "        The ``SCRIPT_NAME`` WSGI environment value.  Setting this to anything\n",
      "        except the empty string will cause the WSGI ``SCRIPT_NAME`` value to be\n",
      "        the value passed minus any trailing slashes you add, and it will cause\n",
      "        the ``PATH_INFO`` of any request which is prefixed with this value to\n",
      "        be stripped of the prefix.  Default is the empty string.\n",
      "\n",
      "    --ident=STR\n",
      "        Server identity used in the 'Server' header in responses. Default\n",
      "        is 'waitress'.\n",
      "\n",
      "Tuning options:\n",
      "\n",
      "    --threads=INT\n",
      "        Number of threads used to process application logic, default is 4.\n",
      "\n",
      "    --backlog=INT\n",
      "        Connection backlog for the server. Default is 1024.\n",
      "\n",
      "    --recv-bytes=INT\n",
      "        Number of bytes to request when calling socket.recv(). Default is\n",
      "        8192.\n",
      "\n",
      "    --send-bytes=INT\n",
      "        Number of bytes to send to socket.send(). Default is 18000.\n",
      "        Multiples of 9000 should avoid partly-filled TCP packets.\n",
      "\n",
      "    --outbuf-overflow=INT\n",
      "        A temporary file should be created if the pending output is larger\n",
      "        than this. Default is 1048576 (1MB).\n",
      "\n",
      "    --outbuf-high-watermark=INT\n",
      "        The app_iter will pause when pending output is larger than this value\n",
      "        and will resume once enough data is written to the socket to fall below\n",
      "        this threshold. Default is 16777216 (16MB).\n",
      "\n",
      "    --inbuf-overflow=INT\n",
      "        A temporary file should be created if the pending input is larger\n",
      "        than this. Default is 524288 (512KB).\n",
      "\n",
      "    --connection-limit=INT\n",
      "        Stop creating new channels if too many are already active.\n",
      "        Default is 100.\n",
      "\n",
      "    --cleanup-interval=INT\n",
      "        Minimum seconds between cleaning up inactive channels. Default\n",
      "        is 30. See '--channel-timeout'.\n",
      "\n",
      "    --channel-timeout=INT\n",
      "        Maximum number of seconds to leave inactive connections open.\n",
      "        Default is 120. 'Inactive' is defined as 'has received no data\n",
      "        from the client and has sent no data to the client'.\n",
      "\n",
      "    --[no-]log-socket-errors\n",
      "        Toggle whether premature client disconnect tracebacks ought to be\n",
      "        logged. On by default.\n",
      "\n",
      "    --max-request-header-size=INT\n",
      "        Maximum size of all request headers combined. Default is 262144\n",
      "        (256KB).\n",
      "\n",
      "    --max-request-body-size=INT\n",
      "        Maximum size of request body. Default is 1073741824 (1GB).\n",
      "\n",
      "    --[no-]expose-tracebacks\n",
      "        Toggle whether to expose tracebacks of unhandled exceptions to the\n",
      "        client. Off by default.\n",
      "\n",
      "    --asyncore-loop-timeout=INT\n",
      "        The timeout value in seconds passed to asyncore.loop(). Default is 1.\n",
      "\n",
      "    --asyncore-use-poll\n",
      "        The use_poll argument passed to ``asyncore.loop()``. Helps overcome\n",
      "        open file descriptors limit. Default is False.\n",
      "\n",
      "    --channel-request-lookahead=INT\n",
      "        Allows channels to stay readable and buffer more requests up to the\n",
      "        given maximum even if a request is already being processed. This allows\n",
      "        detecting if a client closed the connection while its request is being\n",
      "        processed. Default is 0.\n",
      "\n",
      "\n",
      "There was an exception (ImportError) importing your module.\n",
      "\n",
      "It had these arguments: \n",
      "1. Numba needs NumPy 1.20 or less\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\Scripts\\mlflow-script.py\", line 10, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\cassio.costa\\AppData\\Roaming\\Python\\Python38\\site-packages\\click\\core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\models\\cli.py\", line 68, in serve\n",
      "    return _get_flavor_backend(\n",
      "  File \"C:\\Users\\cassio.costa\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\pyfunc\\backend.py\", line 261, in serve\n",
      "    raise Exception(\n",
      "Exception: Command 'waitress-serve --host=127.0.0.1 --port=5002 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'sqlite:///mlruns.db'\n",
    "\n",
    "!mlflow models serve -m \"models:/modelo_projeto/Staging\" --no-conda -p 5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3395dbf0-75f8-48a5-a7f6-0e9d6cfe1e3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSchema",
     "evalue": "No connection adapters were found for 'sqlite:///mlruns.db'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSchema\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      7\u001b[0m http_data \u001b[38;5;241m=\u001b[39m data_operation\u001b[38;5;241m.\u001b[39mdrop(kobe_target_col,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m data_operation\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperation_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(r\u001b[38;5;241m.\u001b[39mtext)\u001b[38;5;241m.\u001b[39mvalues[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m data_operation\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Modeling/modelo_kobe_operacao.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:695\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m hooks \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mhooks\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Get the appropriate adapter to use\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m adapter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;66;03m# Start time (approximately) of the request\u001b[39;00m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:792\u001b[0m, in \u001b[0;36mSession.get_adapter\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m adapter\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66;03m# Nothing matches :-/\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidSchema(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo connection adapters were found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mInvalidSchema\u001b[0m: No connection adapters were found for 'sqlite:///mlruns.db'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "host = 'localhost'\n",
    "port = '5002'\n",
    "url = f'sqlite:///mlruns.db'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "http_data = data_operation.drop(kobe_target_col,axis=1).to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)\n",
    "data_operation.loc[:, 'operation_label'] = pd.read_json(r.text).values[:,0]\n",
    "data_operation.to_parquet('Data/Modeling/modelo_kobe_operacao.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e290adcd-3efd-4908-a583-6ae2c80319f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'operation_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'operation_label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(data_operation[kobe_target_col], \u001b[43mdata_operation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moperation_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'operation_label'"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(data_operation[kobe_target_col], data_operation['operation_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71d42c-146c-48ca-a18e-0a0549f4e383",
   "metadata": {},
   "source": [
    "Consumir o Serviço do Kobe Bryant\n",
    "Este modelo não é aderente a base colocada pois.\n",
    "\n",
    "Em relação a base de 3 pontos, o modelo também não deverá ter uma boa performance, por conta do modelo já ter um desempenho ruim na base de 2 pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832fc9c-d350-4abf-beba-9f966c22f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5002/invocations -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"lat\\\", \\\"lon\\\", \\\"minutes_remaining\\\", \\\"period\\\",\\\"playoffs\\\",\\\"shot_distance\\\"],\\\"data\\\":[[35.9913,-120.3178,8,4,0,7],[33.9703,-118.2908,11,3,0,7]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07ffc2c7-dfdc-40ee-8e15-bfdf6b678bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSchema",
     "evalue": "No connection adapters were found for 'sqlite:///mlruns.db'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSchema\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m http_data \u001b[38;5;241m=\u001b[39m df_kobe_3p\u001b[38;5;241m.\u001b[39mdrop(kobe_target_col,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:695\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    692\u001b[0m hooks \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mhooks\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# Get the appropriate adapter to use\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m adapter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;66;03m# Start time (approximately) of the request\u001b[39;00m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:792\u001b[0m, in \u001b[0;36mSession.get_adapter\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m adapter\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66;03m# Nothing matches :-/\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidSchema(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo connection adapters were found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mInvalidSchema\u001b[0m: No connection adapters were found for 'sqlite:///mlruns.db'"
     ]
    }
   ],
   "source": [
    "http_data = df_kobe_3p.drop(kobe_target_col,axis=1).to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c9216f9-fe6e-4d75-934b-4089184ee2ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_kobe_3p\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperation_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[43mr\u001b[49m\u001b[38;5;241m.\u001b[39mtext)\u001b[38;5;241m.\u001b[39mvalues[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(df_kobe_3p[kobe_target_col], df_kobe_3p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperation_label\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "df_kobe_3p.loc[:, 'operation_label'] = pd.read_json(r.text).values[:,0]\n",
    "\n",
    "print(metrics.classification_report(df_kobe_3p[kobe_target_col], df_kobe_3p['operation_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08af77b6-a952-4f3e-89fc-20ebf9f84cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3630\n",
       "1.0    1782\n",
       "Name: shot_made_flag, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kobe_3p[kobe_target_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5866ef2-21bf-4dba-ac21-d025a09ec8c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'operation_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'operation_label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_kobe_3p\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moperation_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'operation_label'"
     ]
    }
   ],
   "source": [
    "df_kobe_3p['operation_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b0a68ec-e8d1-47fe-b097-e2e673d8dec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /invocations (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E093728CA0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001E093728CA0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /invocations (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E093728CA0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      7\u001b[0m http_data \u001b[38;5;241m=\u001b[39m data_operation\u001b[38;5;241m.\u001b[39mdrop(kobe_target_col,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /invocations (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E093728CA0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "host = 'localhost'\n",
    "port = '5000'\n",
    "url = f'http://{host}:{port}/invocations'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "http_data = data_operation.drop(kobe_target_col,axis=1).to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725d896-1259-4127-bc2a-22f8ec8d717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:5000/invocations -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"lat\\\", \\\"lon\\\", \\\"minutes_remaining\\\", \\\"period\\\",\\\"playoffs\\\",\\\"shot_distance\\\"],\\\"data\\\":[[35.9913,-120.3178,8,4,0,7],[33.9703,-118.2908,11,3,0,7]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177b962-f569-4e26-ae48-477c90a55880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kobe_3p['operation_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbeb14-1053-4b08-a034-2f82e313e103",
   "metadata": {},
   "source": [
    "Pipeline para os Monitoramento dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO MONITORAMENTO\n",
    "\n",
    "MLFlow - É utilizado para registrar os experimentos e treinamentos da base dos dados para comparar na aprovação dos dados e recuperar os dados do modelo. Além de gravar os dados colocados no modelo\n",
    "\n",
    "PyCaret - Auxilia para fazer a predição dos modelos resgatados pelo Mlflow além das configurações utilizadas nos modelos.\n",
    "\n",
    "Scikit-Learn - É utilizado para fazer os calculos das métricas dos modelos selecionados\n",
    "\n",
    "Aprovação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21227b-14cf-42d4-bb45-5707b78ac6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_accuracy = 0.5\n",
    "model_version = -1 # recuperar a ultima versao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3094c-0407-4ad1-a266-ae6b6b330f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCAR RUN APROVACAO DE MODELO\n",
    "# PARAMETROS: min_accuracy\n",
    "# METRICS: new_version, accuracy\n",
    "# ARTIFACTS: None\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'AprovacaoModelo'):\n",
    "    pred_holdout = pc.predict_model(bestmodel[0])\n",
    "    acc = metrics.accuracy_score(pred_holdout[kobe_target_col], pred_holdout['Label'])\n",
    "    if acc > min_precision:\n",
    "        print(f'=> Aceito o modelo com precisão {acc} (min: {min_accuracy})')\n",
    "        pred_holdout.to_parquet('../Data/Processed/modelo_kobe_teste.parquet')\n",
    "        # Assinatura do Modelo Inferida pelo MLFlow\n",
    "        model_features = list(df_kobe.drop(kobe_target_col, axis=1).columns)\n",
    "        inf_signature = infer_signature(df_kobe[model_features], model_pipe.predict(df_kobe))\n",
    "        # Exemplo de entrada para o MLmodel\n",
    "        input_example = {x: df_kobe[x].values[:nexamples] for x in model_features}\n",
    "        # Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_pipe,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            registered_model_name=registered_model_name,\n",
    "            signature = inf_signature,\n",
    "            input_example = input_example\n",
    "        )\n",
    "        # Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "        client = MlflowClient()\n",
    "        if model_version == -1:\n",
    "            model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "        # Registrar o modelo como staging\n",
    "        client.transition_model_version_stage(\n",
    "            name=registered_model_name,\n",
    "            version=model_version, # Verificar com usuario qual versao\n",
    "            stage=\"Staging\"\n",
    "        )\n",
    "    else:\n",
    "        print(f'=> Rejeitado o modelo com precisão {acc} (min: {min_accuracy})')\n",
    "\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"precisao_minima\", min_accuracy)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"new_version\", model_version)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7edecf-dda6-4e12-922b-3ac829abd319",
   "metadata": {},
   "source": [
    "Revalidacao de Amostras para Monitoramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a586d1-3e67-4cb6-8914-c5634f255c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOCAR RUN REVALIDACAO\n",
    "# PARAMETROS: min_samples_control\n",
    "# METRICS: matriz de confusao\n",
    "# ARTIFACTS:\n",
    "\n",
    "\n",
    "# Utilizacao da amostra de controle, que teria sido reavaliada por especialistas\n",
    "min_samples_control = 150\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'RevalidacaoOperacao'):\n",
    "\n",
    "    data_operation = pd.read_parquet('../Data/Modeling/modelo_kobe_operacao.parquet')\n",
    "\n",
    "    data_control = data_operation.sample(min_samples_control, random_state=SEED)\n",
    "    data_control.to_parquet('../Data/Processed/modelo_kobe_controle.parquet')\n",
    "\n",
    "    print('== DADOS DE CONTROLE ==')\n",
    "    print(metrics.classification_report(data_control[kobe_target_col], data_control['operation_label']))\n",
    "    \n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"min_samples_control\", min_samples_control)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    cm = metrics.confusion_matrix(data_control[kobe_target_col], data_control['operation_label'])\n",
    "    specificity = cm[0,0] / cm.sum(axis=1)[0]\n",
    "    sensibility = cm[1,1] / cm.sum(axis=1)[1]\n",
    "    precision   = cm[1,1] / cm.sum(axis=0)[1]\n",
    "    mlflow.log_metric(\"Especificidade\", specificity)\n",
    "    mlflow.log_metric(\"Sensibilidade\", sensibility)\n",
    "    mlflow.log_metric(\"Precisao\", precision)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571da333-b3f2-4648-9349-29a65b83cf4e",
   "metadata": {},
   "source": [
    "Alarme de Desvio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1ae3250-3097-4c4d-9d68-c6b22a8cdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset matplotlib\n",
    "\n",
    "mpl.rcParams.update(inline_rc)\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "mpl.rc('font', **font)\n",
    "lines = {'linewidth' : 3}\n",
    "mpl.rc('lines', **lines)\n",
    "\n",
    "def data_drift_alarm(var_name, dev_data, data_test, data_control):    \n",
    "    sn.kdeplot(dev_data[var_name], label='Desenvolvimento')\n",
    "    sn.kdeplot(data_test[var_name], label='Teste')\n",
    "    sn.kdeplot(data_control[var_name], label='Monitoramento')\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(f'Distribuição Variável {var_name}')\n",
    "    plt.ylabel('Distancia')\n",
    "    plt.xlabel(f'Unidade de {var_name}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95bd71-4811-4858-ac19-04d01f1bdcc7",
   "metadata": {},
   "source": [
    "Alarme de Retreinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7950dd9-e894-4d19-9203-04121a25425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alarm(data_monitoring, testset, min_eff_alarm):\n",
    "    cm = metrics.confusion_matrix(data_monitoring[kobe_target_col], data_monitoring['operation_label'])\n",
    "    specificity_m = cm[0,0] / cm.sum(axis=1)[0]\n",
    "    sensibility_m = cm[1,1] / cm.sum(axis=1)[1]\n",
    "    precision_m   = cm[1,1] / cm.sum(axis=0)[1]\n",
    "\n",
    "    cm = metrics.confusion_matrix(testset[kobe_target_col], testset['Label'])\n",
    "    specificity_t = cm[0,0] / cm.sum(axis=1)[0]\n",
    "    sensibility_t = cm[1,1] / cm.sum(axis=1)[1]\n",
    "    precision_t   = cm[1,1] / cm.sum(axis=0)[1]\n",
    "\n",
    "    retrain = False\n",
    "    for name, metric_m, metric_t in zip(['especificidade', 'sensibilidade', 'precisao'],\n",
    "                                        [specificity_m, sensibility_m, precision_m],\n",
    "                                        [specificity_t, sensibility_t, precision_t]):\n",
    "        \n",
    "        print(f'\\t=> {name} de teste {metric_t} e de controle {metric_m}')\n",
    "        if (metric_t-metric_m)/metric_t > min_eff_alarm:\n",
    "            print(f'\\t=> MODELO OPERANDO FORA DO ESPERADO')\n",
    "            retrain = True\n",
    "        else:\n",
    "            print(f'\\t=> MODELO OPERANDO DENTRO DO ESPERADO')\n",
    "           \n",
    "        \n",
    "    return (retrain, [specificity_m, sensibility_m, precision_m],\n",
    "                                        [specificity_t, sensibility_t, precision_t] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4601f96-518d-4a0b-8356-d47ea85ac9b1",
   "metadata": {},
   "source": [
    "Monitoramento Base Operação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fde9242-d73a-4cb5-94f1-005de0c053e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== ALARME DE RETREINAMENTO - BASE CONTROLE ==\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Run with UUID 8b75a1b59a48450b937b4fa7b50287d0 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 10% de desvio aceitavel na metrica. Deve ser estimado pelo conjunto de validacao cruzada. \u001b[39;00m\n\u001b[0;32m      8\u001b[0m min_eff_alarm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonitoramentoOperacao\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m     data_control \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/Processed/modelo_kobe_controle.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m     (retrain, [specificity_m, sensibility_m, precision_m],\n\u001b[0;32m     14\u001b[0m               [specificity_t, sensibility_t, precision_t] ) \u001b[38;5;241m=\u001b[39m alarm(data_control, pred_holdout, min_eff_alarm)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\tracking\\fluent.py:271\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags, description)\u001b[0m\n\u001b[0;32m    269\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         (\n\u001b[0;32m    273\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    277\u001b[0m     )\n\u001b[0;32m    278\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID 8b75a1b59a48450b937b4fa7b50287d0 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "# COLOCAR RUN MONITORAMENTO OPERACAO\n",
    "# PARAMETROS: min_eff_alarm\n",
    "# METRICS: metricas avaliadas e de referencia\n",
    "# ARTIFACTS:\n",
    "\n",
    "print('== ALARME DE RETREINAMENTO - BASE CONTROLE ==')\n",
    "# 10% de desvio aceitavel na metrica. Deve ser estimado pelo conjunto de validacao cruzada. \n",
    "min_eff_alarm = 0.1 \n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'MonitoramentoOperacao'):\n",
    "    data_control = pd.read_parquet('../Data/Processed/modelo_kobe_controle.parquet')\n",
    "    \n",
    "    (retrain, [specificity_m, sensibility_m, precision_m],\n",
    "              [specificity_t, sensibility_t, precision_t] ) = alarm(data_control, pred_holdout, min_eff_alarm)\n",
    "    if retrain:\n",
    "        print('==> RETREINAMENTO NECESSARIO')\n",
    "    else:\n",
    "        print('==> RETREINAMENTO NAO NECESSARIO')\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"min_eff_alarm\", min_eff_alarm)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"Alarme Retreino\", float(retrain))\n",
    "    mlflow.log_metric(\"Especificidade Controle\", specificity_m)\n",
    "    mlflow.log_metric(\"Sensibilidade Controle\", sensibility_m)\n",
    "    mlflow.log_metric(\"Precisao Controle\", precision_m)\n",
    "    mlflow.log_metric(\"Especificidade Teste\", specificity_t)\n",
    "    mlflow.log_metric(\"Sensibilidade Teste\", sensibility_t)\n",
    "    mlflow.log_metric(\"Precisao Teste\", precision_t)\n",
    "    \n",
    "    # LOG ARTEFATO\n",
    "    var_name = 'shot_distance' # 'alcohol'\n",
    "    data_drift_alarm(var_name, df_kobe, pred_holdout, data_control)\n",
    "    plot_path = f'monitor_datadrift_{var_name}.png'\n",
    "    plt.savefig(plot_path)\n",
    "    mlflow.log_artifact(plot_path)\n",
    "    \n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91022008-fbf6-48dd-b8b3-a3fb6bafd064",
   "metadata": {},
   "source": [
    "Pipeline para a Atualização dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NA ATUALIZAÇÃO\n",
    "\n",
    "MLFlow - É utilizado para a criação de APIs e a criação dos modelos desenvolvidos para o log, além disso é possivel utilizar através da API para outras bases\n",
    "\n",
    "PyCaret - Criação de artefatos e grava parametros e metricas\n",
    "\n",
    "Scikit-Learn - Faz o carregamento do modelo dos dados gravados no Mlflow\n",
    "\n",
    "Monitoramento Base de Novidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78ae6006-8d6d-4625-b987-ca876dcc54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== ALARME DE RETREINAMENTO - BASE NOVIDADE ==\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Run with UUID 8b75a1b59a48450b937b4fa7b50287d0 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 10% de desvio aceitavel na metrica. Deve ser estimado pelo conjunto de validacao cruzada. \u001b[39;00m\n\u001b[0;32m      8\u001b[0m min_eff_alarm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonitoramentoNovidade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     12\u001b[0m     model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/modelo_kobe/Staging\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mload_model(model_uri)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Projeto\\lib\\site-packages\\mlflow\\tracking\\fluent.py:271\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags, description)\u001b[0m\n\u001b[0;32m    269\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         (\n\u001b[0;32m    273\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    277\u001b[0m     )\n\u001b[0;32m    278\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID 8b75a1b59a48450b937b4fa7b50287d0 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "# COLOCAR RUN MONITORAMENTO NOVIDADE\n",
    "# PARAMETROS: min_eff_alarm\n",
    "# METRICS: metricas avaliadas e de referencia\n",
    "# ARTIFACTS:\n",
    "\n",
    "print('== ALARME DE RETREINAMENTO - BASE NOVIDADE ==')\n",
    "# 10% de desvio aceitavel na metrica. Deve ser estimado pelo conjunto de validacao cruzada. \n",
    "min_eff_alarm = 0.1 \n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'MonitoramentoNovidade'):\n",
    "\n",
    "    model_uri = f\"models:/modelo_kobe/Staging\"\n",
    "    loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "    data_novelty = pd.read_parquet('../Data/Processed/base_kobe_novidade.parquet')\n",
    "    data_novelty.loc[:, 'operation_label'] = loaded_model.predict(data_novelty)\n",
    "    \n",
    "    (retrain, [specificity_m, sensibility_m, precision_m],\n",
    "              [specificity_t, sensibility_t, precision_t] ) = alarm(data_novelty, pred_holdout, min_eff_alarm)\n",
    "    if retrain:\n",
    "        print('==> RETREINAMENTO NECESSARIO')\n",
    "    else:\n",
    "        print('==> RETREINAMENTO NAO NECESSARIO')\n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"min_eff_alarm\", min_eff_alarm)\n",
    "\n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"Alarme Retreino\", float(retrain))\n",
    "    mlflow.log_metric(\"Especificidade Controle\", specificity_m)\n",
    "    mlflow.log_metric(\"Sensibilidade Controle\", sensibility_m)\n",
    "    mlflow.log_metric(\"Precisao Controle\", precision_m)\n",
    "    mlflow.log_metric(\"Especificidade Teste\", specificity_t)\n",
    "    mlflow.log_metric(\"Sensibilidade Teste\", sensibility_t)\n",
    "    mlflow.log_metric(\"Precisao Teste\", precision_t)\n",
    "    # LOG ARTEFATO\n",
    "    var_name = 'shot_distance' # 'alcohol'\n",
    "    data_drift_alarm(var_name, df_kobe, pred_holdout, data_novelty)\n",
    "    plot_path = f'novidade_datadrift_{var_name}.png'\n",
    "    plt.savefig(plot_path)\n",
    "    mlflow.log_artifact(plot_path)\n",
    "\n",
    "mlflow.end_run()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e633274-749c-45f0-88e9-744b43a49752",
   "metadata": {},
   "source": [
    "Pipeline para o Provisionamento dos Dados Kobe Bryant\n",
    "IMPORTANCIA DAS FERRAMENTAS NO PROVISIONAMENTO\n",
    "\n",
    "\n",
    "MLFlow - É utilizado para a transição do modelo para a produção\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "806339b3-b2df-47ef-a07f-c34578770bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/20 22:58:47 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\CASSIO~1.COS\\AppData\\Local\\Temp\\tmpz_zxh92s\\model\\model.pkl, flavor: sklearn), fall back to return ['scikit-learn==0.23.2', 'cloudpickle==2.2.0']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'modelo_projeto' already exists. Creating a new version of this model...\n",
      "2022/09/20 22:58:47 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: modelo_projeto, version 4\n",
      "Created version '4' of model 'modelo_projeto'.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     model_version \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_latest_versions(registered_model_name)\u001b[38;5;241m.\u001b[39mversion\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Registrar o modelo como staging\u001b[39;00m\n\u001b[0;32m     14\u001b[0m client\u001b[38;5;241m.\u001b[39mtransition_model_version_stage(\n\u001b[0;32m     15\u001b[0m      name\u001b[38;5;241m=\u001b[39mregistered_model_name,\n\u001b[1;32m---> 16\u001b[0m      version\u001b[38;5;241m=\u001b[39m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_latest_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m, \u001b[38;5;66;03m# Verificar com usuario qual versao\u001b[39;00m\n\u001b[0;32m     17\u001b[0m      stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mend_run()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "# Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "mlflow.sklearn.log_model(\n",
    "     sk_model=model_pipe,\n",
    "     artifact_path=\"sklearn-model\",\n",
    "     registered_model_name=registered_model_name,\n",
    "     signature = inf_signature,\n",
    "     input_example = input_example\n",
    " )\n",
    "# Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "client = MlflowClient()\n",
    "if model_version == -1:\n",
    "    model_version = client.get_latest_versions(registered_model_name).version\n",
    "# Registrar o modelo como staging\n",
    "client.transition_model_version_stage(\n",
    "     name=registered_model_name,\n",
    "     version=client.get_latest_versions(registered_model_name).version, # Verificar com usuario qual versao\n",
    "     stage=\"Production\"\n",
    ")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78505e71-5e3a-4daa-872b-bea92859834e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
